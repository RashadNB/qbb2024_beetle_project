geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "blue", size = 1.5)
maxcoverage = max(coverage$V1)
normal_estimates = 1000000*dnorm(0:maxcoverage, 3, sqrt(3))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs)), color = "red", size = 2) +
# Overlay Normal distribution
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "blue", size = 1.5))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs)), color = "red", size = 2) +
# Overlay Normal distribution
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "blue"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs)), color = "poisson", size = 2) +
# Overlay Normal distribution
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs)), color = "poisson", size = 2) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "poisson", size = 2)) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "poisson"), size = 2) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "poisson"), size = 2) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal"), size = 2) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "Poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "Normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red"))
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "Poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "Normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red")) +
ylab("Frequency")
# Load coverage data from text file
overage <- read.delim("~/qbb2024-answers/week1/coverage2.txt", header = FALSE)
poissonCoverage = coverage %>% dplyr::mutate(Poisson = 1000000*dpois(0:999999,3))
# Load coverage data from text file
overage <- read.delim("~/qbb2024-answers/week1/coverage2.txt", header = FALSE)
poissonCoverage = coverage %>% dplyr::mutate(Poisson = 1000000*dpois(0:999999,3))
# Create a sequence of integer x-values for Poisson (discrete distribution)
lambda <- 10
x_values <- 0:max(coverage$V1)  # Use range of coverage data
poisson_probs <- dpois(x_values, lambda)
maxcoverage = max(coverage$V1)
normal_estimates = 1000000*dnorm(0:maxcoverage, 3, sqrt(3))
# Create a data frame for Poisson distribution
poisson_df <- data.frame(x = x_values, y = poisson_probs)
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "Poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "Normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red")) +
ylab("Frequency")
maxcoverage = max(coverage$V1)
normal_estimates = 1000000*dnorm(0:maxcoverage, 10, sqrt(10))
# Create a data frame for Poisson distribution
poisson_df <- data.frame(x = x_values, y = poisson_probs)
# Load coverage data from text file
coverage <- read.delim("~/qbb2024-answers/week1/coverage2.txt", header = FALSE)
poissonCoverage = coverage %>% dplyr::mutate(Poisson = 1000000*dpois(0:999999,3))
# Create a sequence of integer x-values for Poisson (discrete distribution)
lambda <- 10
x_values <- 0:max(coverage$V1)  # Use range of coverage data
poisson_probs <- dpois(x_values, lambda)
maxcoverage = max(coverage$V1)
normal_estimates = 1000000*dnorm(0:maxcoverage, 10, sqrt(10))
# Create a data frame for Poisson distribution
poisson_df <- data.frame(x = x_values, y = poisson_probs)
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "Poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "Normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red")) +
ylab("Frequency")
# Load coverage data from text file
coverage <- read.delim("~/qbb2024-answers/week1/coverage3.txt", header = FALSE)
# Load coverage data from text file
coverage <- read.delim("~/qbb2024-answers/week1/coverage3.txt", header = FALSE)
poissonCoverage = coverage %>% dplyr::mutate(Poisson = 1000000*dpois(0:999999,3))
# Create a sequence of integer x-values for Poisson (discrete distribution)
lambda <- 30
x_values <- 0:max(coverage$V1)  # Use range of coverage data
poisson_probs <- dpois(x_values, lambda)
maxcoverage = max(coverage$V1)
normal_estimates = 1000000*dnorm(0:maxcoverage, 30, sqrt(30))
# Create a data frame for Poisson distribution
poisson_df <- data.frame(x = x_values, y = poisson_probs)
# Plot the histogram of the coverage data
ggplot() +
# Histogram from the coverage data
geom_histogram(data = coverage,
mapping = aes(x = V1, y = after_stat(count)),
binwidth = 1,
fill = "skyblue",
color = "white") +
# Add labels and theme
labs(title = "Coverage Distribution with Poisson(λ = 3) and Normal Distribution",
x = "Coverage",
y = "Counts") +
theme_minimal() +
# Overlay Poisson distribution
geom_smooth(data = poisson_df, aes(x = x, y = y * length(coverage$V1) / sum(poisson_probs), color = "Poisson")) +
geom_smooth(aes(x = 0:maxcoverage, y = normal_estimates, color = "Normal")) +
scale_color_manual(values = c(Poisson = "blue" , Normal = "red")) +
ylab("Frequency")
library(tidyverse)
library(ggthemes)
# read in the snp_counts file generated in exercise 2.1 and save as a new dataframe
snp_enrichment <- read_tsv("~/qbb2024-answers/week2/snp_counts.txt")
# add a column to the snp_enrichment dataframe that displays the log2-transformed enrichment values
snp_enrichment <- snp_enrichment %>%
dplyr::mutate(log2_enrichment = log2(Enrichment + 1.0))
# plot the data from the snp_enrichment dataframe using ggplot, with MAF on the x-axis and log2_enrichment on the y-axis
# geom_line - specify that the lines should be determined based on the genomic feature, not the MAF
ggplot(data = snp_enrichment,
mapping = aes(x = MAF, y = log2_enrichment)) +
geom_line(data = snp_enrichment,
mapping = aes(color = Feature)) +
scale_color_colorblind(name = "Genomic Feature") +
labs(
title = "SNP enrichment in different genomic features",
subtitle = "Enrichment compared across different minor allele frequencies",
x = "Minor Allele Frequency (MAF)",
y = "SNP Enrichment (log2)"
)
# save the plot generated above as a pdf
ggsave(filename = "~/qbb2024-answers/week2/snp_enrichments.pdf")
snp_enrichment <- snp_enrichment %>%
dplyr::mutate(log2_enrichment = log2(Enrichment + 1.0)) #log2 transforming enrichment.
# plot the data from the snp_enrichment dataframe using ggplot, with MAF on the x-axis and log2_enrichment on the y-axis
# geom_line - specify that the lines should be determined based on the genomic feature, not the MAF
ggplot(data = snp_enrichment, mapping = aes(x = MAF, y = log2_enrichment)) +
geom_line(data = snp_enrichment,
mapping = aes(color = Feature)) +
labs(
title = "SNP enrichment of genomic features",
x = "Minor Allele Frequency",
y = "SNP Enrichment (log2)")
ggsave(filename = "~/qbb2024-answers/week2/snp_enrichments.pdf")
library(tidyverse)
df <- read_csv(file = "~/qbb2024-answers/Week 3/Allele_Frequencies.txt")
df <- read_csv(file = "~/qbb2024-answers/week3/Allele_Frequencies.txt")
df <- read_csv(file = "~/qbb2024-answers/week3/AF.txt")
dr <- read_csv((file="~/qbb2024-answers/week3/DP.txt"))
ggplot(data=df) +
geom_histogram(bins=11,mapping=aes(`Allele Frequency`))
ggplot(data=dr) +
geom_histogram(bins=21,mapping=aes(`Depth Reads`))+
xlim(0,20)
setwd("/Users/cmdb/Desktop/qbb_project/Project_work/Elytron")
# Load necessary packages
library(geomorph)
library(ggplot2)
library(dplyr)
library(viridisLite)
library(viridis)
library(plotly)
tps_file <- "Elytron.TPS"
landmark_data <- readland.tps(tps_file, specID = "ID")  # Assuming "ID" contains the specimen IDs
# Extract the file of origin from the TPS file
lines <- readLines(tps_file)
file_origin <- gsub("^Original_File_ID=", "", lines[grep("^Original_File_ID=", lines)])  # Extract file origin
# Create a new variable for Tribe (just the file origin)
tribe <- factor(file_origin)  # Convert to factor for grouping
# Perform Procrustes alignment (GPA)
gpa_result <- gpagen(landmark_data)
# Perform PCA on the aligned shapes using geomorph's gm.prcomp
pca_result <- gm.prcomp(gpa_result$coords)
# Extract the variance explained by PC1 and PC2
explained_variance <- 100 * (pca_result$sdev^2 / sum(pca_result$sdev^2))
# Create informative axis labels
pc1_label <- paste0("PC1 (", round(explained_variance[1], 2), "% variance)")
pc2_label <- paste0("PC2 (", round(explained_variance[2], 2), "% variance)")
# Extract PCA scores and prepare data for plotting
pca_scores <- as.data.frame(pca_result$x)  # PCA scores from gm.prcomp
colnames(pca_scores) <- paste0("PC", 1:ncol(pca_scores))  # Ensure column names are PC1, PC2, etc.
pca_scores$Tribe <- tribe  # Add Tribe as a factor
# Create convex hulls for each tribe
hulls <- pca_scores %>%
group_by(Tribe) %>%
filter(n() > 2) %>%  # Only keep tribes with more than two points
slice(chull(PC1, PC2))  # Find the convex hull points
# PCA plot with ggplot
pca_plot <- ggplot() +
geom_polygon(data = hulls, aes(x = PC1, y = PC2, fill = Tribe, group = Tribe), alpha = 0.2, show.legend = FALSE) + # Draw hulls first
geom_point(data = pca_scores, aes(x = PC1, y = PC2, color = Tribe, text = rownames(pca_scores)), size = 0.5) + # Then draw points on top
labs(title = "Shape of Stag Beetle Elytra",
x = pc1_label,
y = pc2_label) +
theme_minimal() +
scale_color_brewer(palette = "Set3") +
scale_fill_brewer(palette = "Set3") +
theme(legend.key.size = unit(3, "mm")) +
guides(color = guide_legend(title = "Tribe", override.aes = list(size = 3)))  # Adjust title only
# Convert to interactive plot
interactive_plot <- ggplotly(pca_plot, tooltip = "text")
# Hide hoverinfo for hulls by adjusting the traces after ggplotly
for (i in seq_along(interactive_plot$x$data)) {
if (interactive_plot$x$data[[i]]$type == "scatter" && interactive_plot$x$data[[i]]$mode == "lines") {
interactive_plot$x$data[[i]]$hoverinfo <- "none"  # Remove tooltips for hulls
}
}
# Show the interactive plot
interactive_plot
# Function to extract landmarks for a specific sample ID from the TPS file
extract_landmarks <- function(tps_file, sample_id) {
# Read the TPS file
tps_data <- readLines(tps_file)
# Initialize variables
sample_landmarks <- NULL
current_entry <- NULL
is_target_sample <- FALSE
for (line in tps_data) {
# Check if the line starts with "ID="
if (grepl(paste0("^ID=", sample_id), line)) {
is_target_sample <- TRUE  # Start capturing landmarks for this sample
current_entry <- c(line)  # Include the ID line
} else if (is_target_sample) {
if (grepl("^LM=", line) || grepl("^[0-9]", line)) {
# If it's a landmark line, append it to the current entry
current_entry <- c(current_entry, line)
} else if (grepl("^ID=", line) && !grepl(paste0("^ID=", sample_id), line)) {
# If we reach a new ID and it's not our target sample, stop capturing
break
}
}
}
# If we captured landmarks, create a matrix
if (!is.null(current_entry) && length(current_entry) > 1) {
sample_landmarks <- matrix(as.numeric(unlist(strsplit(current_entry[-1], " "))), ncol = 2, byrow = TRUE)
}
return(sample_landmarks)
}
# Specify the TPS file and the sample ID you want to plot
tps_file <- "Elytron.TPS"
sample_id <- "1167"  # Change this to the ID of the sample you want to plot
# Extract landmarks for the specific sample
sample_landmarks <- extract_landmarks(tps_file, sample_id)
# Check if landmarks were successfully extracted
if (is.null(sample_landmarks)) {
stop("No landmarks found for the specified sample ID.")
}
# Create a data frame for plotting
landmark_df <- data.frame(x = sample_landmarks[, 1], y = sample_landmarks[, 2])
# Plot the shape using ggplot2
ggplot(landmark_df, aes(x = x, y = y)) +
geom_point(size = 1) +  # Plot the landmarks
geom_path(size = 1, color = "blue") +  # Connect the landmarks
labs(title = paste("Shape of Sample ID:", sample_id),
x = "X Coordinate", y = "Y Coordinate") +
theme_minimal()
setwd("/Users/cmdb/Desktop/qbb_project/Project_work/Pronotum")
tps_file <- "Pronotum.TPS"
landmark_data <- readland.tps(tps_file, specID = "ID")  # Assuming "ID" contains the specimen IDs
# Extract the file of origin from the TPS file
lines <- readLines(tps_file)
file_origin <- gsub("^Original_File_ID=", "", lines[grep("^Original_File_ID=", lines)])  # Extract file origin
# Create a new variable for Tribe (just the file origin)
tribe <- factor(file_origin)  # Convert to factor for grouping
# Perform Procrustes alignment (GPA)
gpa_result <- gpagen(landmark_data)
# Perform PCA on the aligned shapes using geomorph's gm.prcomp
pca_result <- gm.prcomp(gpa_result$coords)
# Extract the variance explained by PC1 and PC2
explained_variance <- 100 * (pca_result$sdev^2 / sum(pca_result$sdev^2))
# Create informative axis labels
pc1_label <- paste0("PC1 (", round(explained_variance[1], 2), "% variance)")
pc2_label <- paste0("PC2 (", round(explained_variance[2], 2), "% variance)")
# Extract PCA scores and prepare data for plotting
pca_scores <- as.data.frame(pca_result$x)  # PCA scores from gm.prcomp
colnames(pca_scores) <- paste0("PC", 1:ncol(pca_scores))  # Ensure column names are PC1, PC2, etc.
pca_scores$Tribe <- tribe  # Add Tribe as a factor
# Create convex hulls for each tribe
hulls <- pca_scores %>%
group_by(Tribe) %>%
filter(n() > 2) %>%  # Only keep tribes with more than two points
slice(chull(PC1, PC2))  # Find the convex hull points
# PCA plot with ggplot
pca_plot <- ggplot() +
geom_polygon(data = hulls, aes(x = PC1, y = PC2, fill = Tribe, group = Tribe), alpha = 0.2, show.legend = FALSE) + # Draw hulls first
geom_point(data = pca_scores, aes(x = PC1, y = PC2, color = Tribe, text = rownames(pca_scores)), size = 0.5) + # Then draw points on top
labs(title = "Shape of Stag Beetle Pronota",
x = pc1_label,
y = pc2_label) +
theme_minimal() +
scale_color_brewer(palette = "Set3") +
scale_fill_brewer(palette = "Set3") +
theme(legend.key.size = unit(3, "mm")) +
guides(color = guide_legend(title = "Tribe", override.aes = list(size = 3)))  # Adjust title only
# Convert to interactive plot
interactive_plot <- ggplotly(pca_plot, tooltip = "text")
# Hide hoverinfo for hulls by adjusting the traces after ggplotly
for (i in seq_along(interactive_plot$x$data)) {
if (interactive_plot$x$data[[i]]$type == "scatter" && interactive_plot$x$data[[i]]$mode == "lines") {
interactive_plot$x$data[[i]]$hoverinfo <- "none"  # Remove tooltips for hulls
}
}
# Show the interactive plot
interactive_plot
# Function to extract landmarks for a specific sample ID from the TPS file
extract_landmarks <- function(tps_file, sample_id) {
# Read the TPS file
tps_data <- readLines(tps_file)
# Initialize variables
sample_landmarks <- NULL
current_entry <- NULL
is_target_sample <- FALSE
for (line in tps_data) {
# Check if the line starts with "ID="
if (grepl(paste0("^ID=", sample_id), line)) {
is_target_sample <- TRUE  # Start capturing landmarks for this sample
current_entry <- c(line)  # Include the ID line
} else if (is_target_sample) {
if (grepl("^LM=", line) || grepl("^[0-9]", line)) {
# If it's a landmark line, append it to the current entry
current_entry <- c(current_entry, line)
} else if (grepl("^ID=", line) && !grepl(paste0("^ID=", sample_id), line)) {
# If we reach a new ID and it's not our target sample, stop capturing
break
}
}
}
# If we captured landmarks, create a matrix
if (!is.null(current_entry) && length(current_entry) > 1) {
sample_landmarks <- matrix(as.numeric(unlist(strsplit(current_entry[-1], " "))), ncol = 2, byrow = TRUE)
}
return(sample_landmarks)
}
# Specify the TPS file and the sample ID you want to plot
tps_file <- "Pronotum.TPS"
sample_id <- "871"  # Change this to the ID of the sample you want to plot
# Extract landmarks for the specific sample
sample_landmarks <- extract_landmarks(tps_file, sample_id)
# Check if landmarks were successfully extracted
if (is.null(sample_landmarks)) {
stop("No landmarks found for the specified sample ID.")
}
# Create a data frame for plotting
landmark_df <- data.frame(x = sample_landmarks[, 1], y = sample_landmarks[, 2])
# Plot the shape using ggplot2
ggplot(landmark_df, aes(x = x, y = y)) +
geom_point(size = 1) +  # Plot the landmarks
geom_path(size = 1, color = "blue") +  # Connect the landmarks
labs(title = paste("Shape of Sample ID:", sample_id),
x = "X Coordinate", y = "Y Coordinate") +
theme_minimal()
